"""
AI Video Marketing System - Main Pipeline
H·ªá th·ªëng t·∫°o video marketing t·ª± ƒë·ªông v·ªõi AI
"""
import os
import sys
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
import json
from datetime import datetime
import argparse

# Add src to path
sys.path.append(str(Path(__file__).parent / "src"))

# Import modules
from image_generation.model_generator import ModelGenerator
from trend_analysis.trend_analyzer import TrendAnalyzer
from content_analysis.content_analyzer import ContentAnalyzer
from script_generation.script_generator import ScriptGenerator
from video_production.video_producer import VideoProducer
from video_editing.video_editor import VideoEditor

# Import config
from configs.config import (
    AI_CONFIG, TREND_CONFIG, CONTENT_CONFIG, 
    VIDEO_CONFIG, MARKETING_CONFIG, OUTPUTS_DIR
)

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AIVideoMarketingSystem:
    """H·ªá th·ªëng AI Video Marketing ho√†n ch·ªânh"""
    
    def __init__(self):
        self.model_generator = None
        self.trend_analyzer = None
        self.content_analyzer = None
        self.script_generator = None
        self.video_producer = None
        self.video_editor = None
        
        # Initialize components
        self._initialize_components()
        
    def _initialize_components(self):
        """Kh·ªüi t·∫°o c√°c component"""
        try:
            logger.info("Initializing AI Video Marketing System...")
            
            # Initialize model generator
            self.model_generator = ModelGenerator(AI_CONFIG["stable_diffusion"])
            logger.info("‚úì Model Generator initialized")
            
            # Initialize trend analyzer
            self.trend_analyzer = TrendAnalyzer(TREND_CONFIG)
            logger.info("‚úì Trend Analyzer initialized")
            
            # Initialize content analyzer
            self.content_analyzer = ContentAnalyzer(AI_CONFIG["openai"])
            logger.info("‚úì Content Analyzer initialized")
            
            # Initialize script generator
            self.script_generator = ScriptGenerator(AI_CONFIG["openai"])
            logger.info("‚úì Script Generator initialized")
            
            # Initialize video producer
            self.video_producer = VideoProducer(VIDEO_CONFIG)
            logger.info("‚úì Video Producer initialized")
            
            # Initialize video editor
            self.video_editor = VideoEditor(VIDEO_CONFIG)
            logger.info("‚úì Video Editor initialized")
            
            logger.info("üéâ All components initialized successfully!")
            
        except Exception as e:
            logger.error(f"Error initializing components: {e}")
            raise
    
    def run_full_pipeline(self, 
                         keywords: List[str],
                         target_product: str = "",
                         video_duration: int = 60,
                         output_dir: Optional[Path] = None) -> Dict[str, Any]:
        """
        Ch·∫°y to√†n b·ªô pipeline t·∫°o video marketing
        
        Args:
            keywords: Danh s√°ch t·ª´ kh√≥a trending
            target_product: S·∫£n ph·∫©m m·ª•c ti√™u
            video_duration: Th·ªùi l∆∞·ª£ng video (gi√¢y)
            output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
            
        Returns:
            Dict[str, Any]: K·∫øt qu·∫£ to√†n b·ªô pipeline
        """
        if output_dir is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_dir = OUTPUTS_DIR / f"pipeline_run_{timestamp}"
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info("üöÄ Starting AI Video Marketing Pipeline...")
        logger.info(f"Keywords: {keywords}")
        logger.info(f"Target Product: {target_product}")
        logger.info(f"Video Duration: {video_duration}s")
        logger.info(f"Output Directory: {output_dir}")
        
        pipeline_results = {
            "pipeline_info": {
                "started_at": datetime.now().isoformat(),
                "keywords": keywords,
                "target_product": target_product,
                "video_duration": video_duration,
                "output_dir": str(output_dir)
            },
            "steps": {}
        }
        
        try:
            # Step 1: T√¨m ki·∫øm xu h∆∞·ªõng
            logger.info("üìä Step 1: Analyzing trends...")
            trending_videos = self.trend_analyzer.search_trending_keywords(
                keywords, max_results=50
            )
            trend_analysis = self.trend_analyzer.analyze_trending_patterns(trending_videos)
            
            # Save trend analysis
            trend_file = output_dir / "trend_analysis.json"
            with open(trend_file, 'w', encoding='utf-8') as f:
                json.dump({
                    "videos": [vars(video) for video in trending_videos],
                    "analysis": trend_analysis
                }, f, indent=2, ensure_ascii=False)
            
            pipeline_results["steps"]["trend_analysis"] = {
                "status": "completed",
                "videos_found": len(trending_videos),
                "output_file": str(trend_file)
            }
            logger.info(f"‚úì Found {len(trending_videos)} trending videos")
            
            # Step 2: Ph√¢n t√≠ch n·ªôi dung
            logger.info("üîç Step 2: Analyzing content...")
            content_analysis = self.content_analyzer.batch_analyze_videos(
                [vars(video) for video in trending_videos[:10]],  # Analyze top 10
                output_dir / "content_analysis"
            )
            
            pipeline_results["steps"]["content_analysis"] = {
                "status": "completed",
                "videos_analyzed": len(content_analysis),
                "output_dir": str(output_dir / "content_analysis")
            }
            logger.info(f"‚úì Analyzed {len(content_analysis)} videos")
            
            # Step 3: T·∫°o ·∫£nh ng∆∞·ªùi m·∫´u
            logger.info("üë§ Step 3: Generating model images...")
            model_config = {
                "gender": "female",
                "age": "young adult",
                "ethnicity": "asian",
                "style": "professional",
                "setting": "studio",
                "clothing": "business casual"
            }
            
            model_portfolio = self.model_generator.create_model_portfolio(
                model_config, output_dir / "model_images"
            )
            
            # Get model images
            model_images = []
            for variation_name, image_paths in model_portfolio["images"].items():
                for image_path in image_paths:
                    from PIL import Image
                    model_images.append(Image.open(image_path))
            
            pipeline_results["steps"]["model_generation"] = {
                "status": "completed",
                "images_generated": len(model_images),
                "output_dir": str(output_dir / "model_images")
            }
            logger.info(f"‚úì Generated {len(model_images)} model images")
            
            # Step 4: T·∫°o k·ªãch b·∫£n
            logger.info("üìù Step 4: Generating script...")
            script = self.script_generator.generate_video_script(
                trend_analysis={"videos": [vars(v) for v in trending_videos], "analysis": trend_analysis},
                content_analysis=content_analysis,
                target_product=target_product,
                video_duration=video_duration
            )
            
            # Save script
            script_file = output_dir / "video_script.json"
            with open(script_file, 'w', encoding='utf-8') as f:
                json.dump(script, f, indent=2, ensure_ascii=False)
            
            pipeline_results["steps"]["script_generation"] = {
                "status": "completed",
                "output_file": str(script_file),
                "success_probability": script.get("insights", {}).get("success_probability", 0)
            }
            logger.info("‚úì Script generated successfully")
            
            # Step 5: S·∫£n xu·∫•t video
            logger.info("üé¨ Step 5: Producing video...")
            video_output_path = output_dir / "main_video.mp4"
            video_info = self.video_producer.create_video_from_script(
                script, model_images, video_output_path
            )
            
            pipeline_results["steps"]["video_production"] = {
                "status": "completed",
                "output_file": str(video_output_path),
                "duration": video_info["duration"]
            }
            logger.info("‚úì Video produced successfully")
            
            # Step 6: Ch·ªânh s·ª≠a video
            logger.info("‚úÇÔ∏è Step 6: Editing final video...")
            final_video_info = self.video_editor.create_final_video(
                [str(video_output_path)], script, output_dir / "final_video.mp4"
            )
            
            pipeline_results["steps"]["video_editing"] = {
                "status": "completed",
                "output_files": final_video_info["output_paths"]
            }
            logger.info("‚úì Final video edited successfully")
            
            # Step 7: T·∫°o clips ng·∫Øn
            logger.info("üì± Step 7: Creating short clips...")
            short_clips = self.video_editor.create_short_clips(
                str(video_output_path), script, output_dir / "short_clips"
            )
            
            pipeline_results["steps"]["short_clips"] = {
                "status": "completed",
                "clips_created": len(short_clips),
                "output_dir": str(output_dir / "short_clips")
            }
            logger.info(f"‚úì Created {len(short_clips)} short clips")
            
            # Pipeline completed
            pipeline_results["pipeline_info"]["completed_at"] = datetime.now().isoformat()
            pipeline_results["pipeline_info"]["status"] = "completed"
            pipeline_results["pipeline_info"]["success"] = True
            
            # Save pipeline results
            results_file = output_dir / "pipeline_results.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(pipeline_results, f, indent=2, ensure_ascii=False)
            
            logger.info("üéâ Pipeline completed successfully!")
            logger.info(f"üìÅ All results saved to: {output_dir}")
            
            return pipeline_results
            
        except Exception as e:
            logger.error(f"‚ùå Pipeline failed: {e}")
            pipeline_results["pipeline_info"]["status"] = "failed"
            pipeline_results["pipeline_info"]["error"] = str(e)
            pipeline_results["pipeline_info"]["completed_at"] = datetime.now().isoformat()
            
            # Save error results
            results_file = output_dir / "pipeline_results.json"
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(pipeline_results, f, indent=2, ensure_ascii=False)
            
            raise
    
    def run_quick_demo(self, output_dir: Optional[Path] = None) -> Dict[str, Any]:
        """
        Ch·∫°y demo nhanh v·ªõi d·ªØ li·ªáu m·∫´u
        
        Args:
            output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
            
        Returns:
            Dict[str, Any]: K·∫øt qu·∫£ demo
        """
        logger.info("üöÄ Running Quick Demo...")
        
        # Demo keywords
        demo_keywords = ["cooking tips", "healthy recipes", "quick meals"]
        demo_product = "Premium Cooking Course"
        
        return self.run_full_pipeline(
            keywords=demo_keywords,
            target_product=demo_product,
            video_duration=45,
            output_dir=output_dir
        )
    
    def run_custom_pipeline(self, 
                          config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ch·∫°y pipeline v·ªõi c·∫•u h√¨nh t√πy ch·ªânh
        
        Args:
            config: C·∫•u h√¨nh pipeline
            
        Returns:
            Dict[str, Any]: K·∫øt qu·∫£ pipeline
        """
        logger.info("üöÄ Running Custom Pipeline...")
        
        return self.run_full_pipeline(
            keywords=config.get("keywords", ["demo"]),
            target_product=config.get("target_product", ""),
            video_duration=config.get("video_duration", 60),
            output_dir=config.get("output_dir")
        )

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description="AI Video Marketing System")
    parser.add_argument("--mode", choices=["demo", "custom", "full"], 
                       default="demo", help="Pipeline mode")
    parser.add_argument("--keywords", nargs="+", 
                       default=["cooking", "tips", "viral"], 
                       help="Trending keywords")
    parser.add_argument("--product", type=str, 
                       default="Cooking Course", 
                       help="Target product")
    parser.add_argument("--duration", type=int, 
                       default=60, 
                       help="Video duration in seconds")
    parser.add_argument("--output", type=str, 
                       help="Output directory")
    
    args = parser.parse_args()
    
    # Initialize system
    system = AIVideoMarketingSystem()
    
    try:
        if args.mode == "demo":
            # Run quick demo
            output_dir = Path(args.output) if args.output else None
            results = system.run_quick_demo(output_dir)
            
        elif args.mode == "custom":
            # Run with custom config
            config = {
                "keywords": args.keywords,
                "target_product": args.product,
                "video_duration": args.duration,
                "output_dir": Path(args.output) if args.output else None
            }
            results = system.run_custom_pipeline(config)
            
        elif args.mode == "full":
            # Run full pipeline
            output_dir = Path(args.output) if args.output else None
            results = system.run_full_pipeline(
                keywords=args.keywords,
                target_product=args.product,
                video_duration=args.duration,
                output_dir=output_dir
            )
        
        # Print summary
        print("\n" + "="*50)
        print("üéâ PIPELINE COMPLETED SUCCESSFULLY!")
        print("="*50)
        print(f"üìÅ Output Directory: {results['pipeline_info']['output_dir']}")
        print(f"‚è±Ô∏è  Duration: {results['pipeline_info'].get('completed_at', 'N/A')}")
        print(f"üìä Videos Found: {results['steps']['trend_analysis']['videos_found']}")
        print(f"üîç Videos Analyzed: {results['steps']['content_analysis']['videos_analyzed']}")
        print(f"üë§ Model Images: {results['steps']['model_generation']['images_generated']}")
        print(f"üìù Script Success Rate: {results['steps']['script_generation']['success_probability']:.1f}/10")
        print(f"üé¨ Video Duration: {results['steps']['video_production']['duration']:.1f}s")
        print(f"üì± Short Clips: {results['steps']['short_clips']['clips_created']}")
        print("="*50)
        
    except Exception as e:
        logger.error(f"Pipeline failed: {e}")
        print(f"\n‚ùå Pipeline failed: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

